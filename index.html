<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>Robots.io by JamesFrost</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Robots.io</h1>
        <h2>Robots.txt parsing library</h2>

        <section id="downloads">
          <a href="https://github.com/JamesFrost/robots.io/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/JamesFrost/robots.io/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/JamesFrost/robots.io" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h1>
<a id="robotsio" class="anchor" href="#robotsio" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="https://sourceforge.net/projects/robotsio/files/latest/download">robots.io</a>
</h1>

<p>Robots.io is a Java library designed to make parsing a websites 'robots.txt' file easy.</p>

<h2>
<a id="how-to-use" class="anchor" href="#how-to-use" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to use</h2>

<p>The <a href="https://github.com/JamesFrost/robots.io/blob/master/src/me/jamesfrost/robotsio/RobotsParser.java">RobotsParser</a> class provides all the functionality to use robots.io.</p>

<p><a href="http://robotsio.sourceforge.net/">The Javadoc for Robots.io can be found here.</a></p>

<h2>
<a id="examples" class="anchor" href="#examples" aria-hidden="true"><span class="octicon octicon-link"></span></a>Examples</h2>

<h3>
<a id="connecting" class="anchor" href="#connecting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Connecting</h3>

<p>To parse the robots.txt for Google with the User-Agent string "test":</p>

<div class="highlight highlight-java"><pre><span class="pl-stj">RobotsParser</span> robotsParser <span class="pl-k">=</span> <span class="pl-k">new</span> <span class="pl-stj">RobotsParser</span>(<span class="pl-s1"><span class="pl-pds">"</span>test<span class="pl-pds">"</span></span>);
robotsParser<span class="pl-k">.</span>connect(<span class="pl-s1"><span class="pl-pds">"</span>http://google.com<span class="pl-pds">"</span></span>);</pre></div>

<p>Alternatively, to parse with no User-Agent, simply leave the constructor blank.<br></p>

<p>You can also pass a domain with a path.</p>

<div class="highlight highlight-java"><pre>robotsParser<span class="pl-k">.</span>connect(<span class="pl-s1"><span class="pl-pds">"</span>http://google.com/example.htm<span class="pl-pds">"</span></span>); <span class="pl-c">//This would also be valid</span></pre></div>

<p>Note: Domains can either be passed in string form or as a <a href="http://docs.oracle.com/javase/7/docs/api/java/net/URL.html">URL</a> object to all methods.</p>

<h3>
<a id="querying" class="anchor" href="#querying" aria-hidden="true"><span class="octicon octicon-link"></span></a>Querying</h3>

<p>To check if a URL is allowed:</p>

<div class="highlight highlight-java"><pre>robotsParser<span class="pl-k">.</span>isAllowed(<span class="pl-s1"><span class="pl-pds">"</span>http://google.com/test<span class="pl-pds">"</span></span>); <span class="pl-c">//Returns true if allowed</span></pre></div>

<p>Or, to get all the rules parsed from the file:</p>

<div class="highlight highlight-java"><pre>robotsParser<span class="pl-k">.</span>getDisallowedPaths(); <span class="pl-c">//This will return an ArrayList of Strings</span></pre></div>

<p>The results parsed are cached in the robotsParser object until the <code>connect()</code> method is called again, overwriting the previously parsed data</p>

<h3>
<a id="politeness" class="anchor" href="#politeness" aria-hidden="true"><span class="octicon octicon-link"></span></a>Politeness</h3>

<p>In the event that all access is denied, a <code>RobotsDisallowedException</code> will be thrown.</p>

<h2>
<a id="url-normalisation" class="anchor" href="#url-normalisation" aria-hidden="true"><span class="octicon octicon-link"></span></a>URL Normalisation</h2>

<p>Domains passed to RobotsParser are normalised to always end in a forward slash.
Disallowed Paths returned will never begin with a forward slash.
This is so that URL's can easily be constructed. For example:</p>

<div class="highlight highlight-java"><pre>robotsParser<span class="pl-k">.</span>getDomain() <span class="pl-k">+</span> robotsParser<span class="pl-k">.</span>getDisallowedPaths()<span class="pl-k">.</span>get(<span class="pl-c1">0</span>); <span class="pl-c">// http://google.com/example.htm</span></pre></div>

<h2>
<a id="licensing" class="anchor" href="#licensing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Licensing</h2>

<p>Robots.io is distributed under the GPL.</p>
      </section>
    </div>

    
  </body>
</html>