{"name":"Robots.io","tagline":"Robots.txt parsing library","body":"<a href=\"https://sourceforge.net/projects/robotsio/files/latest/download\">robots.io</a>\r\n=========\r\nRobots.io is a Java library designed to make parsing a websites 'robots.txt' file easy.\r\n\r\n## How to use\r\n<p>The <a href = \"https://github.com/JamesFrost/robots.io/blob/master/src/me/jamesfrost/robotsio/RobotsParser.java\">RobotsParser</a> class provides all the functionality to use robots.io.</p>\r\n<a href=\"http://robotsio.sourceforge.net/\">The Javadoc for Robots.io can be found here.</a>\r\n\r\n## Examples\r\n\r\n### Connecting\r\nTo parse the robots.txt for Google with the User-Agent string \"test\":\r\n```java\r\nRobotsParser robotsParser = new RobotsParser(\"test\");\r\nrobotsParser.connect(\"http://google.com\");\r\n```\r\nAlternatively, to parse with no User-Agent, simply leave the constructor blank.<br>\r\n\r\nYou can also pass a domain with a path.\r\n```java\r\nrobotsParser.connect(\"http://google.com/example.htm\"); //This would also be valid\r\n```\r\nNote: Domains can either be passed in string form or as a <a href=\"http://docs.oracle.com/javase/7/docs/api/java/net/URL.html\">URL</a> object to all methods.\r\n\r\n### Querying\r\nTo check if a URL is allowed:\r\n```java\r\nrobotsParser.isAllowed(\"http://google.com/test\"); //Returns true if allowed\r\n```\r\n\r\nOr, to get all the rules parsed from the file:\r\n```java\r\nrobotsParser.getDisallowedPaths(); //This will return an ArrayList of Strings\r\n```\r\n\r\nThe results parsed are cached in the robotsParser object until the ```connect()``` method is called again, overwriting the previously parsed data\r\n\r\n### Politeness\r\nIn the event that all access is denied, a ```RobotsDisallowedException``` will be thrown.\r\n\r\n## URL Normalisation\r\nDomains passed to RobotsParser are normalised to always end in a forward slash.\r\nDisallowed Paths returned will never begin with a forward slash.\r\nThis is so that URL's can easily be constructed. For example:\r\n```java\r\nrobotsParser.getDomain() + robotsParser.getDisallowedPaths().get(0); // http://google.com/example.htm\r\n```\r\n\r\n## Licensing\r\nRobots.io is distributed under the GPL.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}